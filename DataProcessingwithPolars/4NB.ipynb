{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ee9ac61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1003, 6)\n",
      "Sample data:\n",
      "shape: (5, 6)\n",
      "┌─────────┬──────────────────────┬──────┬────────┬─────────────────────┬──────────┐\n",
      "│ user_id ┆ email                ┆ age  ┆ salary ┆ signup_date         ┆ status   │\n",
      "│ ---     ┆ ---                  ┆ ---  ┆ ---    ┆ ---                 ┆ ---      │\n",
      "│ i64     ┆ str                  ┆ i32  ┆ i32    ┆ datetime[μs]        ┆ str      │\n",
      "╞═════════╪══════════════════════╪══════╪════════╪═════════════════════╪══════════╡\n",
      "│ 999     ┆ user999@example.com  ┆ 64   ┆ 142573 ┆ 2026-09-25 00:00:00 ┆ inactive │\n",
      "│ 1000    ┆ user1000@example.com ┆ 66   ┆ 149076 ┆ 2026-09-26 00:00:00 ┆ inactive │\n",
      "│ 1       ┆ invalid-email        ┆ -5   ┆ 0      ┆ null                ┆ pending  │\n",
      "│ 2       ┆                      ┆ 150  ┆ -1000  ┆ null                ┆ active   │\n",
      "│ 3       ┆ null                 ┆ null ┆ null   ┆ 2030-01-01 00:00:00 ┆ active   │\n",
      "└─────────┴──────────────────────┴──────┴────────┴─────────────────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Sample dataset with quality issues\n",
    "np.random.seed(42)\n",
    "sample_data = pl.DataFrame({\n",
    "    'user_id': list(range(1, 1001)) + [1, 2, 3],  # Duplicates\n",
    "    'email': [f'user{i}@example.com' for i in range(1, 1001)] + ['invalid-email', '', None],\n",
    "    'age': list(np.random.randint(18, 80, 1000)) + [-5, 150, None],  # Invalid ages\n",
    "    'salary': list(np.random.randint(30000, 150000, 1000)) + [0, -1000, None],  # Invalid salaries\n",
    "    'signup_date': [datetime(2024, 1, 1) + timedelta(days=i) for i in range(1000)] + [None, None, datetime(2030, 1, 1)],  # Future date\n",
    "    'status': np.random.choice(['active', 'inactive', 'pending'], 1003)\n",
    "})\n",
    "\n",
    "print(f\"Dataset shape: {sample_data.shape}\")\n",
    "print(\"Sample data:\")\n",
    "print(sample_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59965a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Value Report:\n",
      "shape: (6, 4)\n",
      "┌─────────────┬────────────┬─────────────────┬──────────┐\n",
      "│ column      ┆ null_count ┆ null_percentage ┆ is_valid │\n",
      "│ ---         ┆ ---        ┆ ---             ┆ ---      │\n",
      "│ str         ┆ i64        ┆ f64             ┆ bool     │\n",
      "╞═════════════╪════════════╪═════════════════╪══════════╡\n",
      "│ user_id     ┆ 0          ┆ 0.0             ┆ true     │\n",
      "│ email       ┆ 1          ┆ 0.1             ┆ false    │\n",
      "│ age         ┆ 1          ┆ 0.1             ┆ false    │\n",
      "│ salary      ┆ 1          ┆ 0.1             ┆ false    │\n",
      "│ signup_date ┆ 2          ┆ 0.2             ┆ false    │\n",
      "│ status      ┆ 0          ┆ 0.0             ┆ true     │\n",
      "└─────────────┴────────────┴─────────────────┴──────────┘\n",
      "\n",
      "Rows with nulls in critical columns: 1\n"
     ]
    }
   ],
   "source": [
    "def check_null_values(df: pl.DataFrame, columns: list = None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Check for null values in specified columns or all columns.\n",
    "    \"\"\"\n",
    "    if columns is None:\n",
    "        columns = df.columns\n",
    "    \n",
    "    null_checks = []\n",
    "    for col in columns:\n",
    "        null_count = df.select(pl.col(col).is_null().sum()).item()\n",
    "        null_percentage = (null_count / df.height) * 100\n",
    "        null_checks.append({\n",
    "            'column': col,\n",
    "            'null_count': null_count,\n",
    "            'null_percentage': round(null_percentage, 2),\n",
    "            'is_valid': null_count == 0\n",
    "        })\n",
    "    \n",
    "    return pl.DataFrame(null_checks)\n",
    "\n",
    "# Check for nulls\n",
    "null_report = check_null_values(sample_data)\n",
    "print(\"Null Value Report:\")\n",
    "print(null_report)\n",
    "\n",
    "# Identify rows with nulls in critical columns\n",
    "critical_columns = ['user_id', 'email']\n",
    "null_rows = sample_data.filter(\n",
    "    pl.any_horizontal([pl.col(col).is_null() for col in critical_columns])\n",
    ")\n",
    "print(f\"\\nRows with nulls in critical columns: {null_rows.height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8da0b721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniqueness Report:\n",
      "user_id: {'total_rows': 1003, 'unique_values': 1000, 'duplicate_count': 3, 'is_unique': False}\n",
      "email: {'total_rows': 1003, 'unique_values': 1003, 'duplicate_count': 0, 'is_unique': True}\n",
      "\n",
      "Duplicate user_id rows: 6\n",
      "shape: (5, 2)\n",
      "┌─────────┬───────────────────┐\n",
      "│ user_id ┆ email             │\n",
      "│ ---     ┆ ---               │\n",
      "│ i64     ┆ str               │\n",
      "╞═════════╪═══════════════════╡\n",
      "│ 1       ┆ user1@example.com │\n",
      "│ 2       ┆ user2@example.com │\n",
      "│ 3       ┆ user3@example.com │\n",
      "│ 1       ┆ invalid-email     │\n",
      "│ 2       ┆                   │\n",
      "└─────────┴───────────────────┘\n"
     ]
    }
   ],
   "source": [
    "def check_uniqueness(df: pl.DataFrame, columns: list) -> dict:\n",
    "    \"\"\"\n",
    "    Check for duplicate values in specified columns.\n",
    "    \"\"\"\n",
    "    uniqueness_report = {}\n",
    "    \n",
    "    for col in columns:\n",
    "        total_count = df.height\n",
    "        unique_count = df.select(pl.col(col).n_unique()).item()\n",
    "        duplicate_count = total_count - unique_count\n",
    "        \n",
    "        uniqueness_report[col] = {\n",
    "            'total_rows': total_count,\n",
    "            'unique_values': unique_count,\n",
    "            'duplicate_count': duplicate_count,\n",
    "            'is_unique': duplicate_count == 0\n",
    "        }\n",
    "    \n",
    "    return uniqueness_report\n",
    "\n",
    "# Check uniqueness\n",
    "uniqueness_report = check_uniqueness(sample_data, ['user_id', 'email'])\n",
    "print(\"Uniqueness Report:\")\n",
    "for col, report in uniqueness_report.items():\n",
    "    print(f\"{col}: {report}\")\n",
    "\n",
    "# Find duplicate rows\n",
    "duplicates = sample_data.filter(\n",
    "    pl.col('user_id').is_duplicated()\n",
    ")\n",
    "print(f\"\\nDuplicate user_id rows: {duplicates.height}\")\n",
    "print(duplicates.select(['user_id', 'email']).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82b3ccf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary:\n",
      "shape: (1, 5)\n",
      "┌────────────┬──────────────┬────────────────┬────────────────────┬────────────┐\n",
      "│ valid_ages ┆ valid_emails ┆ valid_salaries ┆ valid_signup_dates ┆ total_rows │\n",
      "│ ---        ┆ ---          ┆ ---            ┆ ---                ┆ ---        │\n",
      "│ u32        ┆ u32          ┆ u32            ┆ u32                ┆ u32        │\n",
      "╞════════════╪══════════════╪════════════════╪════════════════════╪════════════╡\n",
      "│ 1000       ┆ 1000         ┆ 1000           ┆ 733                ┆ 1003       │\n",
      "└────────────┴──────────────┴────────────────┴────────────────────┴────────────┘\n",
      "\n",
      "Invalid records: 270\n",
      "shape: (5, 9)\n",
      "┌─────────┬─────┬──────────────┬────────┬───┬───────────┬─────────────┬──────────────┬─────────────┐\n",
      "│ user_id ┆ age ┆ email        ┆ salary ┆ … ┆ age_valid ┆ email_valid ┆ salary_valid ┆ signup_date │\n",
      "│ ---     ┆ --- ┆ ---          ┆ ---    ┆   ┆ ---       ┆ ---         ┆ ---          ┆ _valid      │\n",
      "│ i64     ┆ i32 ┆ str          ┆ i32    ┆   ┆ bool      ┆ bool        ┆ bool         ┆ ---         │\n",
      "│         ┆     ┆              ┆        ┆   ┆           ┆             ┆              ┆ bool        │\n",
      "╞═════════╪═════╪══════════════╪════════╪═══╪═══════════╪═════════════╪══════════════╪═════════════╡\n",
      "│ 734     ┆ 62  ┆ user734@exam ┆ 65954  ┆ … ┆ true      ┆ true        ┆ true         ┆ false       │\n",
      "│         ┆     ┆ ple.com      ┆        ┆   ┆           ┆             ┆              ┆             │\n",
      "│ 735     ┆ 28  ┆ user735@exam ┆ 57856  ┆ … ┆ true      ┆ true        ┆ true         ┆ false       │\n",
      "│         ┆     ┆ ple.com      ┆        ┆   ┆           ┆             ┆              ┆             │\n",
      "│ 736     ┆ 46  ┆ user736@exam ┆ 32573  ┆ … ┆ true      ┆ true        ┆ true         ┆ false       │\n",
      "│         ┆     ┆ ple.com      ┆        ┆   ┆           ┆             ┆              ┆             │\n",
      "│ 737     ┆ 73  ┆ user737@exam ┆ 108344 ┆ … ┆ true      ┆ true        ┆ true         ┆ false       │\n",
      "│         ┆     ┆ ple.com      ┆        ┆   ┆           ┆             ┆              ┆             │\n",
      "│ 738     ┆ 53  ┆ user738@exam ┆ 65367  ┆ … ┆ true      ┆ true        ┆ true         ┆ false       │\n",
      "│         ┆     ┆ ple.com      ┆        ┆   ┆           ┆             ┆              ┆             │\n",
      "└─────────┴─────┴──────────────┴────────┴───┴───────────┴─────────────┴──────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "def validate_age_range(df: pl.DataFrame, min_age: int = 0, max_age: int = 120) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Validate age values are within reasonable range.\n",
    "    \"\"\"\n",
    "    return df.with_columns([\n",
    "        pl.when(\n",
    "            (pl.col('age').is_null()) |\n",
    "            (pl.col('age') < min_age) |\n",
    "            (pl.col('age') > max_age)\n",
    "        )\n",
    "        .then(pl.lit(False))\n",
    "        .otherwise(pl.lit(True))\n",
    "        .alias('age_valid')\n",
    "    ])\n",
    "\n",
    "def validate_email_format(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Basic email format validation.\n",
    "    \"\"\"\n",
    "    email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
    "    \n",
    "    return df.with_columns([\n",
    "        pl.when(\n",
    "            pl.col('email').is_null() |\n",
    "            ~pl.col('email').str.contains(email_pattern)\n",
    "        )\n",
    "        .then(pl.lit(False))\n",
    "        .otherwise(pl.lit(True))\n",
    "        .alias('email_valid')\n",
    "    ])\n",
    "\n",
    "def validate_salary_range(df: pl.DataFrame, min_salary: int = 1000) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Validate salary values.\n",
    "    \"\"\"\n",
    "    return df.with_columns([\n",
    "        pl.when(\n",
    "            (pl.col('salary').is_null()) |\n",
    "            (pl.col('salary') < min_salary)\n",
    "        )\n",
    "        .then(pl.lit(False))\n",
    "        .otherwise(pl.lit(True))\n",
    "        .alias('salary_valid')\n",
    "    ])\n",
    "\n",
    "def validate_date_range(df: pl.DataFrame, min_date: datetime = None, max_date: datetime = None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Validate date values are within reasonable range.\n",
    "    \"\"\"\n",
    "    if min_date is None:\n",
    "        min_date = datetime(2020, 1, 1)\n",
    "    if max_date is None:\n",
    "        max_date = datetime.now()\n",
    "    \n",
    "    return df.with_columns([\n",
    "        pl.when(\n",
    "            (pl.col('signup_date').is_null()) |\n",
    "            (pl.col('signup_date') < min_date) |\n",
    "            (pl.col('signup_date') > max_date)\n",
    "        )\n",
    "        .then(pl.lit(False))\n",
    "        .otherwise(pl.lit(True))\n",
    "        .alias('signup_date_valid')\n",
    "    ])\n",
    "\n",
    "# Apply validations\n",
    "validated_data = (\n",
    "    sample_data\n",
    "    .pipe(validate_age_range)\n",
    "    .pipe(validate_email_format)\n",
    "    .pipe(validate_salary_range)\n",
    "    .pipe(validate_date_range)\n",
    ")\n",
    "\n",
    "# Summary of validation results\n",
    "validation_summary = validated_data.select([\n",
    "    pl.col('age_valid').sum().alias('valid_ages'),\n",
    "    pl.col('email_valid').sum().alias('valid_emails'),\n",
    "    pl.col('salary_valid').sum().alias('valid_salaries'),\n",
    "    pl.col('signup_date_valid').sum().alias('valid_signup_dates'),\n",
    "    pl.len().alias('total_rows')\n",
    "])\n",
    "\n",
    "print(\"Validation Summary:\")\n",
    "print(validation_summary)\n",
    "\n",
    "# Show invalid records\n",
    "invalid_records = validated_data.filter(\n",
    "    ~pl.col('age_valid') |\n",
    "    ~pl.col('email_valid') |\n",
    "    ~pl.col('salary_valid') |\n",
    "    ~pl.col('signup_date_valid')\n",
    ")\n",
    "\n",
    "print(f\"\\nInvalid records: {invalid_records.height}\")\n",
    "print(invalid_records.select(['user_id', 'age', 'email', 'salary', 'signup_date', 'age_valid', 'email_valid', 'salary_valid', 'signup_date_valid']).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12541d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema Validation Report:\n",
      "Valid: False\n",
      "Missing columns: []\n",
      "Extra columns: []\n",
      "Type mismatches: [{'column': 'age', 'expected': 'Int64', 'actual': 'Int32'}, {'column': 'salary', 'expected': 'Int64', 'actual': 'Int32'}]\n"
     ]
    }
   ],
   "source": [
    "def validate_schema(df: pl.DataFrame, expected_schema: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Validate DataFrame schema against expected structure.\n",
    "    \n",
    "    expected_schema: {'column_name': pl.DataType}\n",
    "    \"\"\"\n",
    "    schema_report = {\n",
    "        'valid': True,\n",
    "        'missing_columns': [],\n",
    "        'extra_columns': [],\n",
    "        'type_mismatches': []\n",
    "    }\n",
    "    \n",
    "    # Check for missing columns\n",
    "    expected_columns = set(expected_schema.keys())\n",
    "    actual_columns = set(df.columns)\n",
    "    \n",
    "    missing = expected_columns - actual_columns\n",
    "    extra = actual_columns - expected_columns\n",
    "    \n",
    "    if missing:\n",
    "        schema_report['missing_columns'] = list(missing)\n",
    "        schema_report['valid'] = False\n",
    "    \n",
    "    if extra:\n",
    "        schema_report['extra_columns'] = list(extra)\n",
    "    \n",
    "    # Check data types for existing columns\n",
    "    for col, expected_type in expected_schema.items():\n",
    "        if col in df.columns:\n",
    "            actual_type = df.schema[col]\n",
    "            if actual_type != expected_type:\n",
    "                schema_report['type_mismatches'].append({\n",
    "                    'column': col,\n",
    "                    'expected': str(expected_type),\n",
    "                    'actual': str(actual_type)\n",
    "                })\n",
    "                schema_report['valid'] = False\n",
    "    \n",
    "    return schema_report\n",
    "\n",
    "# Define expected schema\n",
    "expected_schema = {\n",
    "    'user_id': pl.Int64,\n",
    "    'email': pl.Utf8,\n",
    "    'age': pl.Int64,\n",
    "    'salary': pl.Int64,\n",
    "    'signup_date': pl.Datetime,\n",
    "    'status': pl.Utf8\n",
    "}\n",
    "\n",
    "# Validate schema\n",
    "schema_validation = validate_schema(sample_data, expected_schema)\n",
    "print(\"Schema Validation Report:\")\n",
    "print(f\"Valid: {schema_validation['valid']}\")\n",
    "if not schema_validation['valid']:\n",
    "    print(f\"Missing columns: {schema_validation['missing_columns']}\")\n",
    "    print(f\"Extra columns: {schema_validation['extra_columns']}\")\n",
    "    print(f\"Type mismatches: {schema_validation['type_mismatches']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e19316c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comprehensive Validation Report:\n",
      "shape: (5, 6)\n",
      "┌─────────────────┬───────────────┬───────────────┬────────────────┬──────────────┬────────────────┐\n",
      "│ rule_name       ┆ total_records ┆ valid_records ┆ invalid_record ┆ success_rate ┆ error_message  │\n",
      "│ ---             ┆ ---           ┆ ---           ┆ s              ┆ ---          ┆ ---            │\n",
      "│ str             ┆ i64           ┆ i64           ┆ ---            ┆ f64          ┆ str            │\n",
      "│                 ┆               ┆               ┆ i64            ┆              ┆                │\n",
      "╞═════════════════╪═══════════════╪═══════════════╪════════════════╪══════════════╪════════════════╡\n",
      "│ positive_age    ┆ 1003          ┆ 1000          ┆ 3              ┆ 99.7         ┆ Age must be    │\n",
      "│                 ┆               ┆               ┆                ┆              ┆ between 1 and  │\n",
      "│                 ┆               ┆               ┆                ┆              ┆ 120            │\n",
      "│ valid_email     ┆ 1003          ┆ 1000          ┆ 3              ┆ 99.7         ┆ Email must be  │\n",
      "│                 ┆               ┆               ┆                ┆              ┆ in valid       │\n",
      "│                 ┆               ┆               ┆                ┆              ┆ format         │\n",
      "│ positive_salary ┆ 1003          ┆ 1000          ┆ 3              ┆ 99.7         ┆ Salary must be │\n",
      "│                 ┆               ┆               ┆                ┆              ┆ at least 1000  │\n",
      "│ valid_status    ┆ 1003          ┆ 1003          ┆ 0              ┆ 100.0        ┆ Status must be │\n",
      "│                 ┆               ┆               ┆                ┆              ┆ active,        │\n",
      "│                 ┆               ┆               ┆                ┆              ┆ inactiv…       │\n",
      "│ recent_signup   ┆ 1003          ┆ 733           ┆ 270            ┆ 73.08        ┆ Signup date    │\n",
      "│                 ┆               ┆               ┆                ┆              ┆ cannot be in   │\n",
      "│                 ┆               ┆               ┆                ┆              ┆ the f…         │\n",
      "└─────────────────┴───────────────┴───────────────┴────────────────┴──────────────┴────────────────┘\n",
      "\n",
      "Overall Data Quality Score:\n",
      "shape: (1, 3)\n",
      "┌─────────────────────┬───────────────┬────────────────────┐\n",
      "│ fully_valid_records ┆ total_records ┆ data_quality_score │\n",
      "│ ---                 ┆ ---           ┆ ---                │\n",
      "│ u32                 ┆ u32           ┆ f64                │\n",
      "╞═════════════════════╪═══════════════╪════════════════════╡\n",
      "│ 733                 ┆ 1003          ┆ 73.080758          │\n",
      "└─────────────────────┴───────────────┴────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "def create_validation_rule(name: str, condition: pl.Expr, error_message: str = None):\n",
    "    \"\"\"\n",
    "    Create a reusable validation rule.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'name': name,\n",
    "        'condition': condition,\n",
    "        'error_message': error_message or f\"Validation failed for {name}\"\n",
    "    }\n",
    "\n",
    "def apply_validation_rules(df: pl.DataFrame, rules: list) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply multiple validation rules to a DataFrame.\n",
    "    \"\"\"\n",
    "    result_df = df\n",
    "    \n",
    "    for rule in rules:\n",
    "        validation_col = f\"{rule['name']}_valid\"\n",
    "        result_df = result_df.with_columns(\n",
    "            rule['condition'].alias(validation_col)\n",
    "        )\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def create_validation_report(df: pl.DataFrame, rules: list) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a comprehensive validation report.\n",
    "    \"\"\"\n",
    "    report_data = []\n",
    "    \n",
    "    for rule in rules:\n",
    "        validation_col = f\"{rule['name']}_valid\"\n",
    "        if validation_col in df.columns:\n",
    "            valid_count = df.select(pl.col(validation_col).sum()).item()\n",
    "            total_count = df.height\n",
    "            invalid_count = total_count - valid_count\n",
    "            \n",
    "            report_data.append({\n",
    "                'rule_name': rule['name'],\n",
    "                'total_records': total_count,\n",
    "                'valid_records': valid_count,\n",
    "                'invalid_records': invalid_count,\n",
    "                'success_rate': round((valid_count / total_count) * 100, 2),\n",
    "                'error_message': rule['error_message']\n",
    "            })\n",
    "    \n",
    "    return pl.DataFrame(report_data)\n",
    "\n",
    "# Define validation rules\n",
    "validation_rules = [\n",
    "    create_validation_rule(\n",
    "        'positive_age',\n",
    "        (pl.col('age') > 0) & (pl.col('age') <= 120),\n",
    "        'Age must be between 1 and 120'\n",
    "    ),\n",
    "    create_validation_rule(\n",
    "        'valid_email',\n",
    "        pl.col('email').str.contains(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'),\n",
    "        'Email must be in valid format'\n",
    "    ),\n",
    "    create_validation_rule(\n",
    "        'positive_salary',\n",
    "        pl.col('salary') >= 1000,\n",
    "        'Salary must be at least 1000'\n",
    "    ),\n",
    "    create_validation_rule(\n",
    "        'valid_status',\n",
    "        pl.col('status').is_in(['active', 'inactive', 'pending']),\n",
    "        'Status must be active, inactive, or pending'\n",
    "    ),\n",
    "    create_validation_rule(\n",
    "        'recent_signup',\n",
    "        pl.col('signup_date') <= datetime.now(),\n",
    "        'Signup date cannot be in the future'\n",
    "    )\n",
    "]\n",
    "\n",
    "# Apply validation rules\n",
    "validated_df = apply_validation_rules(sample_data, validation_rules)\n",
    "\n",
    "# Generate validation report\n",
    "validation_report = create_validation_report(validated_df, validation_rules)\n",
    "print(\"Comprehensive Validation Report:\")\n",
    "print(validation_report)\n",
    "\n",
    "# Create overall data quality score\n",
    "validation_columns = [f\"{rule['name']}_valid\" for rule in validation_rules]\n",
    "overall_quality = validated_df.with_columns(\n",
    "    pl.all_horizontal([pl.col(col) for col in validation_columns]).alias('all_valid')\n",
    ").select(\n",
    "    pl.col('all_valid').sum().alias('fully_valid_records'),\n",
    "    pl.len().alias('total_records')\n",
    ").with_columns(\n",
    "    (pl.col('fully_valid_records') / pl.col('total_records') * 100).alias('data_quality_score')\n",
    ")\n",
    "\n",
    "print(\"\\nOverall Data Quality Score:\")\n",
    "print(overall_quality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ef5edcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Validation Report:\n",
      "shape: (3, 2)\n",
      "┌─────────────────┬──────────────┐\n",
      "│ rule_name       ┆ success_rate │\n",
      "│ ---             ┆ ---          │\n",
      "│ str             ┆ f64          │\n",
      "╞═════════════════╪══════════════╡\n",
      "│ positive_age    ┆ 99.7         │\n",
      "│ valid_email     ┆ 99.7         │\n",
      "│ positive_salary ┆ 99.7         │\n",
      "└─────────────────┴──────────────┘\n",
      "\n",
      "Final Validation Report (after cleaning):\n",
      "shape: (3, 2)\n",
      "┌─────────────────┬──────────────┐\n",
      "│ rule_name       ┆ success_rate │\n",
      "│ ---             ┆ ---          │\n",
      "│ str             ┆ f64          │\n",
      "╞═════════════════╪══════════════╡\n",
      "│ positive_age    ┆ 99.7         │\n",
      "│ valid_email     ┆ 99.7         │\n",
      "│ positive_salary ┆ 99.7         │\n",
      "└─────────────────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "class DataQualityPipeline:\n",
    "    def __init__(self):\n",
    "        self.validation_rules = []\n",
    "        self.cleaning_rules = []\n",
    "    \n",
    "    def add_validation_rule(self, name: str, condition: pl.Expr, error_message: str = None):\n",
    "        self.validation_rules.append({\n",
    "            'name': name,\n",
    "            'condition': condition,\n",
    "            'error_message': error_message or f\"Validation failed for {name}\"\n",
    "        })\n",
    "        return self\n",
    "    \n",
    "    def add_cleaning_rule(self, name: str, transformation: pl.Expr):\n",
    "        self.cleaning_rules.append({\n",
    "            'name': name,\n",
    "            'transformation': transformation\n",
    "        })\n",
    "        return self\n",
    "    \n",
    "    def validate(self, df: pl.DataFrame) -> tuple[pl.DataFrame, pl.DataFrame]:\n",
    "        \"\"\"Return validated DataFrame and validation report\"\"\"\n",
    "        validated_df = apply_validation_rules(df, self.validation_rules)\n",
    "        report = create_validation_report(validated_df, self.validation_rules)\n",
    "        return validated_df, report\n",
    "    \n",
    "    def clean(self, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        \"\"\"Apply cleaning transformations\"\"\"\n",
    "        result_df = df\n",
    "        for rule in self.cleaning_rules:\n",
    "            result_df = result_df.with_columns(rule['transformation'])\n",
    "        return result_df\n",
    "    \n",
    "    def process(self, df: pl.DataFrame) -> tuple[pl.DataFrame, pl.DataFrame, pl.DataFrame]:\n",
    "        \"\"\"Full pipeline: validate, clean, re-validate\"\"\"\n",
    "        # Initial validation\n",
    "        validated_df, initial_report = self.validate(df)\n",
    "        \n",
    "        # Clean data\n",
    "        cleaned_df = self.clean(validated_df)\n",
    "        \n",
    "        # Re-validate after cleaning\n",
    "        final_validated_df, final_report = self.validate(cleaned_df)\n",
    "        \n",
    "        return final_validated_df, initial_report, final_report\n",
    "\n",
    "# Create and configure pipeline\n",
    "pipeline = DataQualityPipeline()\n",
    "\n",
    "# Add validation rules\n",
    "(pipeline\n",
    " .add_validation_rule('positive_age', (pl.col('age') > 0) & (pl.col('age') <= 120))\n",
    " .add_validation_rule('valid_email', pl.col('email').str.contains(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'))\n",
    " .add_validation_rule('positive_salary', pl.col('salary') >= 1000)\n",
    ")\n",
    "\n",
    "# Add cleaning rules\n",
    "(pipeline\n",
    " .add_cleaning_rule('clean_email', pl.col('email').str.to_lowercase().str.strip_chars())\n",
    " .add_cleaning_rule('cap_age', pl.when(pl.col('age') > 120).then(pl.lit(None)).otherwise(pl.col('age')))\n",
    " .add_cleaning_rule('fix_negative_salary', pl.when(pl.col('salary') < 0).then(pl.lit(None)).otherwise(pl.col('salary')))\n",
    ")\n",
    "\n",
    "# Process data\n",
    "processed_df, initial_report, final_report = pipeline.process(sample_data)\n",
    "\n",
    "print(\"Initial Validation Report:\")\n",
    "print(initial_report.select(['rule_name', 'success_rate']))\n",
    "print(\"\\nFinal Validation Report (after cleaning):\")\n",
    "print(final_report.select(['rule_name', 'success_rate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd5bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of using Great Expectations with Polars\n",
    "# Note: This requires great_expectations and the Polars integration\n",
    "\n",
    "# import great_expectations as gx\n",
    "# from great_expectations.datasource.fluent import PolarsDatasource\n",
    "\n",
    "# # Create Great Expectations context\n",
    "# context = gx.get_context()\n",
    "\n",
    "# # Add Polars datasource\n",
    "# datasource = context.sources.add_polars(\"polars_datasource\")\n",
    "\n",
    "# # Add data asset\n",
    "# data_asset = datasource.add_dataframe_asset(\n",
    "#     name=\"user_data\",\n",
    "#     dataframe=sample_data\n",
    "# )\n",
    "\n",
    "# # Create expectations\n",
    "# batch_request = data_asset.build_batch_request()\n",
    "# validator = context.get_validator(batch_request=batch_request)\n",
    "\n",
    "# # Add expectations\n",
    "# validator.expect_column_values_to_not_be_null(\"user_id\")\n",
    "# validator.expect_column_values_to_be_unique(\"user_id\")\n",
    "# validator.expect_column_values_to_be_between(\"age\", min_value=0, max_value=120)\n",
    "# validator.expect_column_values_to_match_regex(\"email\", r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$')\n",
    "\n",
    "# # Run validation\n",
    "# results = validator.validate()\n",
    "# print(\"Great Expectations Results:\")\n",
    "# print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorial-env (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
